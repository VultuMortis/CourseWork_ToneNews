Курсовая работа по теме:
"Онлайн мониторинг тональности русскоязычных новостей"
(или более общее название дисциплины, если оно было, например, "Применение методов машинного обучения для анализа текстовых данных")

Автор: [Ваше Имя и Фамилия]

О проекте
Проект представляет собой исследование и разработку системы для автоматического определения тональности (позитивная/негативная) русскоязычных новостных текстов. Работа включает полный цикл Data Science проекта: от сбора и предварительного анализа данных до построения, сравнения различных моделей машинного обучения и реализации прототипа Telegram-бота для онлайн-мониторинга тональности новостей по URL.

Основные этапы работы
Загрузка и предварительный анализ данных

Использование датасета "Kaggle Russian News Dataset".

Исследование распределения классов тональности.

Удаление нерелевантных данных (нейтральная тональность, дубликаты – если удаляли).

Анализ характеристик текстовых данных.

Предварительная обработка текста

Для классических моделей:

Приведение к нижнему регистру.

Удаление пунктуации и специальных символов.

Токенизация текста (библиотека NLTK).

Удаление стоп-слов русского языка.

Для модели RuBERT:

Использование специализированного токенизатора (BertTokenizer от Hugging Face).

Векторизация текста

TF-IDF (Term Frequency-Inverse Document Frequency): Для классических моделей, с использованием униграмм и биграмм.

Контекстуальные эмбеддинги BERT: Для модели RuBERT, генерация эмбеддингов на основе предобученной русскоязычной модели.

Построение, обучение и оценка моделей машинного обучения

Модель на основе RuBERT:

Архитектура с добавлением классификационного слоя.

Обучение с использованием PyTorch, оптимизатора AdamW и функции потерь CrossEntropyLoss с весами классов.

Оценка на валидационной и тестовой выборках.

Альтернативные ("классические") модели на TF-IDF признаках:

Логистическая регрессия (LogisticRegression).

Метод опорных векторов (LinearSVC).

Градиентный бустинг (CatBoostClassifier).

Простая полносвязная нейронная сеть (реализована на PyTorch).

Оценка моделей проводилась с использованием метрик: Accuracy, Precision, Recall, F1-score (Macro, Weighted), ROC AUC.

Сравнительный анализ моделей и выбор наилучшей

Сопоставление результатов всех моделей.

Визуализация сравнительных метрик.

Обоснование выбора модели для использования в прототипе.

Разработка прототипа Telegram-бота

Реализация бота на Python с использованием библиотеки python-telegram-bot.

Интеграция выбранной модели (RuBERT) для анализа тональности.

Функционал парсинга текста новостей по URL (библиотеки requests и BeautifulSoup).

Предоставление результата анализа пользователю.

Технологии
Python 3.x

Среда разработки: Jupyter Notebook / Google Colab

Библиотеки для обработки данных:

Pandas

NumPy

Библиотеки для обработки естественного языка (NLP):

NLTK

re (встроенная)

Библиотеки для машинного обучения и глубокого обучения:

Scikit-learn (TF-IDF, Logistic Regression, LinearSVC, метрики, GridSearchCV)

PyTorch (реализация RuBERT-классификатора, простой НС, обучение)

Transformers (Hugging Face) (доступ к RuBERT и токенизатору)

CatBoost

Библиотеки для визуализации:

Matplotlib

Seaborn

Библиотеки для Telegram-бота:

python-telegram-bot

requests

BeautifulSoup4

nest_asyncio (для работы в Jupyter/Colab)

Вспомогательные библиотеки:

tqdm

time

logging

os
